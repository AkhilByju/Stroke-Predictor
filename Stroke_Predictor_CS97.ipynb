{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AkhilByju/Stroke-Predictor/blob/main/Stroke_Predictor_CS97.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iplXxNtRVzI2"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # this is used for the plot the graph\n",
        "import os\n",
        "import seaborn as sns # used for plot interactive graph.\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.metrics.cluster as smc\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "\n",
        "from matplotlib import pyplot\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import random\n",
        "\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YuknrFq4XAeh"
      },
      "outputs": [],
      "source": [
        "# Helper function allowing you to export a graph\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsoAkNnEXDxw"
      },
      "outputs": [],
      "source": [
        "# Helper function that allows you to draw nicely formatted confusion matrices\n",
        "def draw_confusion_matrix(y, yhat, classes):\n",
        "    '''\n",
        "        Draws a confusion matrix for the given target and predictions\n",
        "        Adapted from scikit-learn and discussion example.\n",
        "    '''\n",
        "    plt.cla()\n",
        "    plt.clf()\n",
        "    matrix = confusion_matrix(y, yhat)\n",
        "    plt.imshow(matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.colorbar()\n",
        "    num_classes = len(classes)\n",
        "    plt.xticks(np.arange(num_classes), classes, rotation=90)\n",
        "    plt.yticks(np.arange(num_classes), classes)\n",
        "\n",
        "    fmt = 'd'\n",
        "    thresh = matrix.max() / 2.\n",
        "    for i, j in itertools.product(range(matrix.shape[0]), range(matrix.shape[1])):\n",
        "        plt.text(j, i, format(matrix[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if matrix[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsMxZ94hpXwv"
      },
      "outputs": [],
      "source": [
        "def print_4_metrics(target_test, predicted):\n",
        "  print(\"%-12s %f\" % ('Accuracy:', metrics.accuracy_score(target_test,predicted)))\n",
        "  print(\"%-12s %f\" % ('Precision:', metrics.precision_score(target_test, predicted,labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
        "  print(\"%-12s %f\" % ('Recall:', metrics.recall_score(target_test, predicted,labels=None, pos_label=1, average='binary', sample_weight=None)))\n",
        "  print(\"%-12s %f\" % ('F1 Score:', metrics.f1_score(target_test, predicted,labels=None, pos_label=1, average='binary', sample_weight=None)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1AXWX15jdzE"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7JzLhINzXiGW"
      },
      "outputs": [],
      "source": [
        "url='https://drive.google.com/file/d/1_U-J7E30JmE8Q7KuMT723dI7QxJAxhAB/view?usp=sharing'\n",
        "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
        "\n",
        "df = pd.read_csv(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMB3qKURXyCB"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2nkbfadZQTs"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FHxpZuD2ZVYI"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_4Jj0y9Zfdu"
      },
      "source": [
        "Deleting ID because this column is not needed in the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9BKNnp-Ze4c"
      },
      "outputs": [],
      "source": [
        "data = df.drop('id', axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6Dys8MnZ1lJ"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUi1_lX6jz1j"
      },
      "source": [
        "Filling in Null Values\n",
        "\n",
        "Median filled into BMI (Median Imputation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiOeuzBdaXlr"
      },
      "outputs": [],
      "source": [
        "median = data[\"bmi\"].median()\n",
        "data[\"bmi\"].fillna(median, inplace=True)\n",
        "null_rows = data[data.isnull().any(axis=1)]\n",
        "null_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f7aDcjckGkM"
      },
      "source": [
        "Replacing Null smoking values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGIHUi_pb8br"
      },
      "outputs": [],
      "source": [
        "data[\"stroke\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mfajR7KfQMY"
      },
      "outputs": [],
      "source": [
        "known_smoking = data[data[\"smoking_status\"] != \"Unknown\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVRDnCrbcn2D"
      },
      "outputs": [],
      "source": [
        "balanced_data = known_smoking.sort_values('stroke', ascending=False).head(404)\n",
        "balanced_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HhL5VSW9rCLE"
      },
      "outputs": [],
      "source": [
        "null_rows = balanced_data[balanced_data.isnull().any(axis=1)] #Used to check if any rows contain null data\n",
        "null_rows"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn6ZU3waMf0G"
      },
      "source": [
        "Preprocessing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXnx9PdpZ4Dz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "\n",
        "# Categorical Features\n",
        "categorical_features = [\"gender\", 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
        "\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "for c in categorical_features:\n",
        "  le.fit(balanced_data[c])\n",
        "  balanced_data[c]=le.transform(balanced_data[c])\n",
        "\n",
        "# Numerical Features\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scale_data = balanced_data[['age', 'avg_glucose_level', 'bmi']]\n",
        "binary_data = balanced_data.drop(['age', 'avg_glucose_level', 'bmi'], axis=1)\n",
        "scaled_data = scaler.fit_transform(scale_data)\n",
        "\n",
        "df_scaled_data = pd.DataFrame(scaled_data, columns=scale_data.columns)\n",
        "# Something is wrong here\n",
        "binary_data = binary_data.reset_index()\n",
        "all_data = pd.concat([df_scaled_data, binary_data], axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_data = all_data.drop(['index'], axis =1)"
      ],
      "metadata": {
        "id": "ROBI4kz1bTa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQWJw0nna9R9"
      },
      "outputs": [],
      "source": [
        "df_correlation = all_data.corr()\n",
        "df_correlation['stroke'].sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkXxAO1dnywb"
      },
      "outputs": [],
      "source": [
        "data_target = all_data[\"stroke\"]\n",
        "data_prepared = all_data.drop(['stroke'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD_J-yns_SDk"
      },
      "outputs": [],
      "source": [
        "data_prepared"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do83yf4UnsAt"
      },
      "source": [
        "# **MODELS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nekZJHo8oIn-"
      },
      "source": [
        "Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkBz6BctoIGQ"
      },
      "outputs": [],
      "source": [
        "train, test, target, target_test = train_test_split(data_prepared, data_target, test_size = 0.2, random_state = 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kieNjNzDoqM9"
      },
      "source": [
        "Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wYUV1AVpFuC"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(penalty = 'l1', solver='liblinear', C = 0.15)\n",
        "\n",
        "log_reg.fit(train, target)\n",
        "\n",
        "log_predicted = log_reg.predict(test)\n",
        "log_score = log_reg.predict_proba(test)[:,1]\n",
        "print_4_metrics(target_test, log_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIZV4OJnGiIY"
      },
      "outputs": [],
      "source": [
        "C_values = []\n",
        "C = 0.1\n",
        "while C < 0.35:\n",
        "  C_values.append(C)\n",
        "  C += 0.05\n",
        "\n",
        "for c in C_values:\n",
        "  log_reg = LogisticRegression(penalty = 'l1', solver='liblinear', C = 0.15)\n",
        "\n",
        "  log_reg.fit(train, target)\n",
        "\n",
        "  log_predicted = log_reg.predict(test)\n",
        "  print(f\"C value: {c}\")\n",
        "  print(f\"Accuracy: {metrics.accuracy_score(target_test,log_predicted)}\", '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdjVYSnb-b6O"
      },
      "outputs": [],
      "source": [
        "print_4_metrics(target_test, log_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hp3OgCVA_yhG"
      },
      "outputs": [],
      "source": [
        "# Plot ROC curve and report area under ROC\n",
        "# use metrics.roc_curve(your y_test, predicted probabilities for y_test)\n",
        "\n",
        "fpr_log_reg, tpr_log_reg, thresholds = metrics.roc_curve(target_test,log_score)\n",
        "print(\"Logistic Model Performance Results:\\n\")\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(fpr_log_reg, tpr_log_reg, color='orange', lw=1)\n",
        "pyplot.title(\"ROC curve with Logistic Regression\")\n",
        "pyplot.xlabel('FPR')\n",
        "pyplot.ylabel('TPR')\n",
        "\n",
        "# report auc\n",
        "# use metrics.auc(fpr, tpr)\n",
        "aucroc = metrics.auc(fpr_log_reg, tpr_log_reg)\n",
        "print('AUC of ROC: ', aucroc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EIM1atXuABeK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(type(log_predicted))\n",
        "draw_confusion_matrix(target_test, log_predicted, ['Stroke', 'No Stroke'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEIslbloor3b"
      },
      "source": [
        "K-Nearest Neighbor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_eRaxAhA8WE"
      },
      "outputs": [],
      "source": [
        "for k in range(1,300):\n",
        "\n",
        "    KNN = KNeighborsClassifier(n_neighbors=k)\n",
        "    KNN.fit(train, target)\n",
        "    KNN_predicted = KNN.predict(test)\n",
        "\n",
        "    print(f\"K value: {k}\")\n",
        "    print(f\"Accuracy: {metrics.accuracy_score(target_test,KNN_predicted)}\", '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mfzZDC6B6lq"
      },
      "outputs": [],
      "source": [
        "KNN = KNeighborsClassifier(n_neighbors=81, algorithm='ball_tree', p=1)\n",
        "\n",
        "KNN.fit(train, target)\n",
        "\n",
        "KNN_predicted = KNN.predict(test)\n",
        "KNN_score = KNN.predict_proba(test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_nl8NssFDDOs"
      },
      "outputs": [],
      "source": [
        "print_4_metrics(target_test, KNN_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS01eUMWDHrI"
      },
      "outputs": [],
      "source": [
        "# Plot ROC curve and report area under ROC\n",
        "# use metrics.roc_curve(your y_test, predicted probabilities for y_test)\n",
        "\n",
        "fpr_KNN, tpr_KNN, thresholds = metrics.roc_curve(target_test,KNN_score)\n",
        "print(\"KNN Model Performance Results:\\n\")\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(fpr_KNN, tpr_KNN, color='orange', lw=1)\n",
        "pyplot.title(\"ROC curve with KNN\")\n",
        "pyplot.xlabel('FPR')\n",
        "pyplot.ylabel('TPR')\n",
        "\n",
        "# report auc\n",
        "# use metrics.auc(fpr, tpr)\n",
        "aucroc = metrics.auc(fpr_KNN, tpr_KNN)\n",
        "print('AUC of ROC: ', aucroc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pumb8HGhFDjC"
      },
      "outputs": [],
      "source": [
        "draw_confusion_matrix(target_test, KNN_predicted, ['Stroke', 'No Stroke'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOtgkPijoukf"
      },
      "source": [
        "Support Vector Machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gh-GpxdoIMsY"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(probability = True, C=.25, kernel=\"sigmoid\", gamma='auto')\n",
        "\n",
        "svm.fit(train, target)\n",
        "\n",
        "svm_predicted = svm.predict(test)\n",
        "\n",
        "svm_score = svm.predict_proba(test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctElx4qRMqai"
      },
      "outputs": [],
      "source": [
        "C_values = []\n",
        "C = 0.1\n",
        "while C < 0.35:\n",
        "  C_values.append(C)\n",
        "  C += 0.05\n",
        "\n",
        "for c in C_values:\n",
        "  svm = SVC(probability = True, C=c, kernel=\"sigmoid\", gamma='auto')\n",
        "  svm.fit(train, target)\n",
        "  svm_predicted = svm.predict(test)\n",
        "\n",
        "  print(f\"C value: {c}\")\n",
        "  print(f\"Accuracy: {print_4_metrics(target_test,svm_predicted)}\", '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGW1E1wuIWUi"
      },
      "outputs": [],
      "source": [
        "print_4_metrics(target_test, svm_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYE2lFNKIZoW"
      },
      "outputs": [],
      "source": [
        "fpr_svm, tpr_svm, thresholds = metrics.roc_curve(target_test,svm_score)\n",
        "print(\"Support Vector Machine Performance Results:\\n\")\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(fpr_svm, tpr_svm, color='orange', lw=1)\n",
        "pyplot.title(\"ROC curve with SVM\")\n",
        "pyplot.xlabel('FPR')\n",
        "pyplot.ylabel('TPR')\n",
        "\n",
        "# report auc\n",
        "# use metrics.auc(fpr, tpr)\n",
        "aucroc = metrics.auc(fpr_svm, tpr_svm)\n",
        "print('AUC of ROC: ', aucroc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKwH0_dUIeUm"
      },
      "outputs": [],
      "source": [
        "draw_confusion_matrix(target_test, svm_predicted, ['Stroke', 'No Stroke'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7CqRpIwov_X"
      },
      "source": [
        "Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNdt7HARgf3M"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
        "\n",
        "tree = DecisionTreeClassifier(max_depth=5, random_state=0)\n",
        "\n",
        "tree.fit(train, target)\n",
        "\n",
        "tree_predicted = tree.predict(test)\n",
        "\n",
        "tree_score = tree.predict_proba(test)[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWItZqwONb_o"
      },
      "outputs": [],
      "source": [
        "for depth in range(1,25):\n",
        "  tree = DecisionTreeClassifier(max_depth=depth, random_state=0)\n",
        "  tree.fit(train, target)\n",
        "  tree_predicted = tree.predict(test)\n",
        "  print(f\"max_depth: {depth}\")\n",
        "  print(f\"Accuracy: {metrics.accuracy_score(target_test,tree_predicted)}\", '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aRR-U1Q2zaO"
      },
      "outputs": [],
      "source": [
        "print_4_metrics(target_test, tree_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5u5usJUgj7t"
      },
      "outputs": [],
      "source": [
        "fpr_tree, tpr_tree, thresholds = metrics.roc_curve(target_test,tree_score)\n",
        "print(\"Decision Tree Performance Results:\\n\")\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(fpr_tree, tpr_tree, color='orange', lw=1)\n",
        "pyplot.title(\"ROC curve with Decision Tree\")\n",
        "pyplot.xlabel('FPR')\n",
        "pyplot.ylabel('TPR')\n",
        "\n",
        "# report auc\n",
        "# use metrics.auc(fpr, tpr)\n",
        "aucroc = metrics.auc(fpr_tree, tpr_tree)\n",
        "print('AUC of ROC: ', aucroc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aq9W9DnygnD9"
      },
      "outputs": [],
      "source": [
        "draw_confusion_matrix(target_test, tree_predicted, ['Stroke', 'No Stroke'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eNTcu8SgsOl"
      },
      "source": [
        "Decision Tree (Random Forest)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkk4Gws4gvUQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rf_tree = RandomForestClassifier(n_estimators=50, random_state=0) # Iterates through 50 different decision trees)\n",
        "\n",
        "rf_tree.fit(train, target)\n",
        "\n",
        "rf_tree_predicted = rf_tree.predict(test)\n",
        "\n",
        "rf_tree_score = rf_tree.predict_proba(test)[:,1]\n",
        "print_4_metrics(target_test, rf_tree_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0br-chA6g52G"
      },
      "outputs": [],
      "source": [
        "fpr_rf_tree, tpr_rf_tree, thresholds = metrics.roc_curve(target_test,rf_tree_score)\n",
        "print(\"Decision Tree (with Random Forest) Performance Results:\\n\")\n",
        "pyplot.figure(1)\n",
        "pyplot.plot(fpr_rf_tree, tpr_rf_tree, color='orange', lw=1)\n",
        "pyplot.title(\"ROC curve with Decision Tree + Random Forest\")\n",
        "pyplot.xlabel('FPR')\n",
        "pyplot.ylabel('TPR')\n",
        "\n",
        "# report auc\n",
        "# use metrics.auc(fpr, tpr)\n",
        "aucroc = metrics.auc(fpr_rf_tree, tpr_rf_tree)\n",
        "print('AUC of ROC: ', aucroc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_rJ5gcvg8D-"
      },
      "outputs": [],
      "source": [
        "draw_confusion_matrix(target_test, rf_tree_predicted, ['Stroke', 'No Stroke'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJjw-pvag_3B"
      },
      "source": [
        "# Visual Model of Trees\n",
        "\n",
        "Links to Generated Images:\n",
        "\n",
        "Decision Tree: https://drive.google.com/file/d/1oR19aWImKc_sSxXKpNyUQL4sQfjck2dB/view?usp=sharing\n",
        "\n",
        "Random Forest Decision Tree (1/100): https://drive.google.com/file/d/1fdtxiOqqent3u3pRRCILexspCsrcX00E/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vvnf8pxhhLNT"
      },
      "outputs": [],
      "source": [
        "# Decision Tree Model\n",
        "import graphviz\n",
        "from sklearn.tree import export_graphviz\n",
        "\n",
        "data = export_graphviz(tree, out_file=None, filled=True, rounded=True, special_characters=True)\n",
        "graph = graphviz.Source(data, format='pdf')\n",
        "graph.render(\"decision_tree\", format='pdf', cleanup=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mYiGq-BhXlU"
      },
      "outputs": [],
      "source": [
        "# The first random forest tree models\n",
        "rf_data = export_graphviz(rf_tree.estimators_[0], out_file=None, filled=True, rounded=True, special_characters=True)\n",
        "rf_graph = graphviz.Source(rf_data, format='pdf')\n",
        "rf_graph.render(\"rf_decision_tree_#1\", format='pdf', cleanup=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImwptrDWo54p"
      },
      "source": [
        "Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU7WvILYvCep"
      },
      "source": [
        "Preprocessing\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfEiNZumvB1g"
      },
      "outputs": [],
      "source": [
        "data_nn = df\n",
        "median = data_nn[\"bmi\"].median()\n",
        "data_nn[\"bmi\"].fillna(median, inplace=True)\n",
        "null_rows = data_nn[data_nn.isnull().any(axis=1)]\n",
        "data_nn[\"stroke\"].value_counts()\n",
        "balanced_data_nn = data_nn[data_nn[\"smoking_status\"] != \"Unknown\"].sort_values('stroke', ascending=False).head(404)\n",
        "gender_map = {'Male': 0,'Female': 1,'Other': 2}\n",
        "ever_married_map = {'No': 0,'Yes': 1}\n",
        "work_type_map = {'children': 0,'Govt_jov': 1,'Never_worked': 2,'Private': 3,'Self-employed': 4}\n",
        "residence_type_map = {'Rural': 0,'Urban': 1}\n",
        "smoking_status_map = {'formerly smoked': 0, 'never smoked': 1, 'smokes': 2, 'Unknown': 3}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y70BWq1sHK2D"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class StrokeDataset(Dataset):\n",
        "    def __init__(self, dataset, normalize=True, feature_transform=None, label_transform=None):\n",
        "        self.feature_transform = feature_transform\n",
        "        self.label_transform = label_transform\n",
        "\n",
        "        #self.df = pd.read_csv(dataset_file_path)\n",
        "        self.df = dataset\n",
        "        # map strings to numbers\n",
        "        self.df['gender'] = self.df['gender'].map(gender_map, na_action='ignore')\n",
        "        self.df['ever_married'] = self.df['ever_married'].map(ever_married_map, na_action='ignore')\n",
        "        self.df['work_type'] = self.df['work_type'].map(work_type_map, na_action='ignore')\n",
        "        self.df['Residence_type'] = self.df['Residence_type'].map(residence_type_map, na_action='ignore')\n",
        "        self.df['smoking_status'] = self.df['smoking_status'].map(smoking_status_map, na_action='ignore')\n",
        "\n",
        "        # remove rows with missing data\n",
        "        self.df.dropna(inplace=True)\n",
        "\n",
        "        # normalize\n",
        "        normalize_data = []\n",
        "\n",
        "        if normalize:\n",
        "            for col in self.df.columns:\n",
        "                normalize_data.append(self.df[col].abs().max())\n",
        "                self.df[col] = self.df[col] / self.df[col].abs().max()\n",
        "        print(normalize_data)\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # https://stackoverflow.com/a/29763653\n",
        "        features = self.df.iloc[index].drop(['stroke', 'id'])\n",
        "        label = self.df['stroke'].iloc[index]\n",
        "\n",
        "        if self.feature_transform:\n",
        "            features = self.feature_transform(features)\n",
        "        if self.label_transform:\n",
        "            label = self.label_transform(label)\n",
        "        return features, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPHKdz566ISJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import time\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "DATASET_SPLIT = 0.8 # n% training data, 1 - n% testing data\n",
        "\n",
        "LEARNING_RATE = 0.01\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 100\n",
        "NORMALIZE = True\n",
        "\n",
        "start_time = time.time()\n",
        "#model_folder_path = 'models/model_3'\n",
        "\n",
        "# Load dataset\n",
        "\n",
        "dataset = StrokeDataset(\n",
        "    balanced_data_nn,\n",
        "    normalize=NORMALIZE,\n",
        "    # convert pandas object to tensor\n",
        "    feature_transform=lambda feature: torch.tensor(feature, dtype=torch.float32),\n",
        "    label_transform=lambda label: torch.reshape(torch.tensor(label, dtype=torch.float32), (-1,))\n",
        ")\n",
        "\n",
        "split_pos = int(len(dataset) * DATASET_SPLIT)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Z8rpi7hGVYa"
      },
      "outputs": [],
      "source": [
        "train_dataset, test_dataset = random_split(dataset, [split_pos, len(dataset) - split_pos])\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86p3iwrME87q"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(10, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 32),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(32, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1),\n",
        "    nn.ReLU(),\n",
        ")\n",
        "\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "def train_loop():\n",
        "    size = len(train_dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(train_dataloader):\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 30 == 0:\n",
        "            loss, current = loss.item(), batch * BATCH_SIZE\n",
        "            print(f'Training MSE Loss: {loss:>7f} [{current:>4d}/{size:>4d}]')\n",
        "\n",
        "def test_loop():\n",
        "    size = len(test_dataloader.dataset)\n",
        "    num_batches = len(test_dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "\n",
        "            pred_answers = (pred > 0.5).float() # 0 or 1 only\n",
        "            correct += torch.sum(torch.logical_not(torch.logical_xor(pred_answers, y))).item()\n",
        "\n",
        "    avg_loss = test_loss / num_batches\n",
        "    accuracy = correct / size\n",
        "    print(f'Test Accuracy: {100 * accuracy:>0.1f}%')\n",
        "    print(f'Test Average loss: {avg_loss:>8f}')\n",
        "\n",
        "# Train and test every epoch\n",
        "\n",
        "try:\n",
        "    for epoch in range(EPOCHS):\n",
        "        print()\n",
        "        print(f'Epoch {epoch + 1}')\n",
        "        print('-' * 20)\n",
        "        train_loop()\n",
        "        test_loop()\n",
        "\n",
        "    print('Finished')\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    print('Finished early')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTExikxtNGbN"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "for inputs, _ in test_dataloader:\n",
        "    # Forward pass\n",
        "    outputs = model(inputs)\n",
        "    #print(outputs)\n",
        "    for output in outputs:\n",
        "      if output >= 0.5:\n",
        "          predicted_labels.append(1)\n",
        "      else:\n",
        "          predicted_labels.append(0)\n",
        "\n",
        "predicted_df = pd.DataFrame({'Predicted Labels': predicted_labels})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSV5ooFG8gc3"
      },
      "outputs": [],
      "source": [
        "true_labels = []\n",
        "for _, labels in test_dataloader:\n",
        "    true_labels.extend(labels.flatten().tolist())\n",
        "true_labels = [int(label) for label in true_labels]\n",
        "true_df = pd.DataFrame({'True Labels': true_labels})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FMYUenkxLvR9"
      },
      "outputs": [],
      "source": [
        "print_4_metrics(true_df, predicted_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2awz4fV85ra"
      },
      "outputs": [],
      "source": [
        "print(true_labels)\n",
        "print(predicted_labels)\n",
        "print(type(true_df))\n",
        "print(type(predicted_df))\n",
        "draw_confusion_matrix(true_df, predicted_df, ['Stroke','No Stroke'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLOwiQyzEtcN"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(true_df, predicted_df)\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5M_ltbbDSci"
      },
      "outputs": [],
      "source": [
        "print_4_metrics(true_df, predicted_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}